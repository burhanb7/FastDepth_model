{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"FastDepthv2_training.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyObE/aLpnoLpcJWjxpl4QKf"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"iaqjvurQelnv"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive/')\n","import sys\n","import os\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0xL7I2hjhNXx"},"source":["prefix = '/content/gdrive/My Drive/'\n","input_path = 'ECE5554_Fall2021/Project/FastDepth_files/'\n","output_path = 'ECE5554_Fall2021/Project/output/'\n","sys_path = os.path.join(prefix, input_path)\n","sys.path.append(sys_path)\n","output_sys_path = os.path.join(prefix, output_path)\n","sys.path.append(output_sys_path)\n","%cd /content/\n","%cd 'gdrive/My Drive/ECE5554_Fall2021/Project/FastDepth_files/'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cbPY_G59mLiC"},"source":["import os\n","import shutil\n","import time\n","import torch\n","import torch.nn as nn\n","import torch.nn.parallel\n","import torch.backends.cudnn as cudnn\n","import torch.optim\n","import torch.utils.data\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from PIL import Image # PIL is the Python Imaging Library\n","import cv2\n","import nyu_transforms\n","import torch.nn.functional as F"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aGR0DQOjis3y"},"source":["def convlayer(in_channels,out_channels,kernel_size,stride):\n","    padding = 1\n","    assert 2*padding == kernel_size-1, \"parameters incorrect. kernel={}, padding={}\".format(kernel_size, padding)\n","    return nn.Sequential(\n","          nn.Conv2d(in_channels,out_channels,kernel_size,stride=stride,padding=padding,bias=False),\n","          nn.BatchNorm2d(out_channels),\n","          nn.ReLU6(inplace=True),\n","        )\n","\n","def mobilenetlayer(in_channels,out_channels,kernel_size,stride):\n","  padding = 1\n","  return nn.Sequential(\n","          nn.Conv2d(in_channels,in_channels,kernel_size,stride=stride,padding=padding,bias=False,groups=in_channels),\n","          nn.BatchNorm2d(in_channels),\n","          nn.ReLU6(inplace=True),\n","          nn.Conv2d(in_channels,out_channels,1,1,0,bias=False),\n","          nn.BatchNorm2d(out_channels),\n","          nn.ReLU6(inplace=True),\n","    )\n","def depthwise(in_channels, kernel_size):\n","    padding = (kernel_size-1) // 2\n","    assert 2*padding == kernel_size-1, \"parameters incorrect. kernel={}, padding={}\".format(kernel_size, padding)\n","    return nn.Sequential(\n","          nn.Conv2d(in_channels,in_channels,kernel_size,stride=1,padding=padding,bias=False,groups=in_channels),\n","          nn.BatchNorm2d(in_channels),\n","          nn.ReLU(inplace=True),\n","        )\n","\n","def pointwise(in_channels, out_channels):\n","    return nn.Sequential(\n","          nn.Conv2d(in_channels,out_channels,1,1,0,bias=False),\n","          nn.BatchNorm2d(out_channels),\n","          nn.ReLU(inplace=True),\n","        )"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"P_FLgLyFiwEM"},"source":["class Encoder(nn.Module):\n","  def __init__(self):\n","        super(Encoder, self).__init__()\n","        kernel_size = 3\n","        self.conv0 = convlayer(3,16,kernel_size,2)\n","        self.conv1 = mobilenetlayer(16,56,kernel_size,1)\n","        self.conv2 = mobilenetlayer(56,88,kernel_size,2)\n","        self.conv3 = mobilenetlayer(88,120,kernel_size,1)\n","        self.conv4 = mobilenetlayer(120,144,kernel_size,2)\n","        self.conv5 = mobilenetlayer(144,256,kernel_size,1)\n","        self.conv6 = mobilenetlayer(256,408,kernel_size,2)\n","        self.conv7 = mobilenetlayer(408,376,kernel_size,1)\n","        self.conv8 = mobilenetlayer(376,272,kernel_size,1)\n","        self.conv9 = mobilenetlayer(272,288,kernel_size,1)\n","        self.conv10 = mobilenetlayer(288,296,kernel_size,1)\n","        self.conv11 = mobilenetlayer(296,328,kernel_size,1)\n","        self.conv12 = mobilenetlayer(328,480,kernel_size,2)\n","        self.conv13 = mobilenetlayer(480,512,kernel_size,1)\n","  def forward(self, x):\n","        for i in range(14):\n","            layer = getattr(self, 'conv{}'.format(i))\n","            x = layer(x)\n","            if i==1:\n","                x1 = x\n","            elif i==3:\n","                x2 = x\n","            elif i==5:\n","                x3 = x\n","        return x,x1,x2,x3"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"d5yAv5IhizVv"},"source":["class Decoder(nn.Module):\n","  def __init__(self):\n","        super(Decoder, self).__init__()\n","        kernel_size = 5\n","        self.decode_conv1 = nn.Sequential(\n","            depthwise(512, kernel_size),\n","            pointwise(512, 200))\n","        self.decode_conv2 = nn.Sequential(\n","            depthwise(200, kernel_size),\n","            pointwise(200, 256))\n","        self.decode_conv3 = nn.Sequential(\n","            depthwise(256, kernel_size),\n","            pointwise(256, 120))\n","        self.decode_conv4 = nn.Sequential(\n","            depthwise(120, kernel_size),\n","            pointwise(120, 56))\n","        self.decode_conv5 = nn.Sequential(\n","            depthwise(56, kernel_size),\n","            pointwise(56, 16))\n","        self.decode_conv6 = pointwise(16, 1)\n","  def forward(self, x,x1,x2,x3):\n","        for i in range(1,6):\n","            layer = getattr(self, 'decode_conv{}'.format(i))\n","            x = layer(x)\n","            x = F.interpolate(x, scale_factor=2, mode='nearest')\n","            if i==4:\n","                x = x + x1\n","            elif i==3:\n","                x = x + x2\n","            elif i==2:\n","                x = x + x3\n","        x = self.decode_conv6(x)\n","        return x\n","        "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PwtJZKc4i1dr"},"source":["class DepthEstimation(nn.Module):\n","  def __init__(self):\n","        super(DepthEstimation, self).__init__()\n","        self.encoder = Encoder()\n","        self.decoder = Decoder()\n","  def forward(self,x):\n","        x,x1,x2,x3 = self.encoder(x)\n","        x = self.decoder(x,x1,x2,x3)\n","        return x"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"M7cHl6KkDGuU"},"source":["from PIL import Image\n","from torchvision import transforms\n","import pickle\n","preprocess = transforms.Compose([\n","            transforms.Resize(224),\n","            transforms.CenterCrop(224),\n","            transforms.ToTensor(),\n","            #transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n","        ])\n","device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n","model.to(device)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mEXql6Wzxkjx"},"source":["dataset = []\n","train_dir = \"KITTI_Train/\"\n","for i in range(21):\n","  print(i)  \n","  pkl_file_name = train_dir+'kitty_dataset_orig_small' +str(i) + '.pkl'\n","  with open(pkl_file_name, 'rb') as pickle_file:\n","      dataset_t = pickle.load(pickle_file)\n","      dataset = dataset + dataset_t"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VPmBMR7MoSqE"},"source":["train_loader = torch.utils.data.DataLoader(dataset, batch_size=64, shuffle=True, num_workers=2)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"elcRK0ufpoSV"},"source":["print(type(train_loader))\n","print(len(train_loader))\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3nvIRGcgo1G5"},"source":["def Solver(model, train_loader, optim, criterion, epoch, lr):\n","  min_loss = 100000000000000\n","  min_loss_epoch = 0\n","  for e in range(epoch):\n","          count = 0\n","          loss_epoch = 0\n","          for x, y in train_loader:\n","            #y = Training_data[filename]\n","            #input_batch = x.unsqueeze(0) # create a mini-batch as expected by the model\n","            shape = [y.shape[1],y.shape[2]]\n","            input_batch = x.to('cuda')\n","            optim.zero_grad()\n","            y_pred = model(input_batch) \n","            prediction = y_pred.reshape(y_pred.shape[0],y_pred.shape[2],y_pred.shape[3])\n","            prediction = torch.nn.functional.interpolate(\n","            prediction.unsqueeze(1),\n","            size=shape,\n","            mode=\"bicubic\",\n","            align_corners=False,\n","            ).squeeze()\n","            output = prediction.cpu()\n","            loss = (criterion(output, y))\n","            if (count % 1000) == 0:\n","              print(loss)\n","            loss.backward()\n","            optim.step()\n","            loss_epoch += loss.item()\n","            count += 1\n","          if loss_epoch <  min_loss:\n","            min_loss = loss_epoch\n","            min_loss_epoch = e\n","            print(str(min_loss) + ' at ' + str(min_loss_epoch))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VRWbcOStckbV"},"source":["lr_variable = 0.0001\n","epoch = 500\n","criterion = nn.MSELoss()\n","optim = torch.optim.Adam(model.parameters(), lr=lr_variable)\n","#optim = torch.optim.SGD(model.parameters(), lr=0.01,momentum=0.9,weight_decay=0.1)\n","Solver(model,train_loader,optim,criterion,epoch,lr_variable)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-AhF8bKX9NFC"},"source":["import time\n","def forward_model_test(raw_img): \n","  input_image = Image.open(raw_img).convert('RGB')\n","  shape = [input_image.size[1],input_image.size[0]]\n","  #shape = [224,224]\n","  input_tensor = preprocess(input_image)\n","  input_batch = input_tensor.unsqueeze(0) # create a mini-batch as expected by the model\n","  input_batch = input_batch.to('cuda')\n","  t1 = time.time()\n","  prediction = model(input_batch)\n","  t2 = time.time()\n","  prediction = prediction.reshape(1,224,224)\n","  prediction = torch.nn.functional.interpolate(\n","      prediction.unsqueeze(1),\n","      size=shape,\n","      mode=\"bicubic\",\n","      align_corners=False,\n","  ).squeeze()\n","\n","  output = prediction.detach().cpu()\n","  return output,(t2-t1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KNuD7a4RUgOn"},"source":["depth_img_folder = 'KITTI_Depth/2011_09_26_drive_0001_sync/proj_depth/groundtruth/image_02/'\n","raw_img_folder = 'KITTI_Raw/2011_09_26_drive_0001_sync/image_02/data/'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7lqCRWl5Oe-v"},"source":["filename_raw_t = raw_img_folder+\"0000000005.png\"\n","y= forward_model_test(filename_raw_t)\n","plt.imshow(y)"],"execution_count":null,"outputs":[]}]}